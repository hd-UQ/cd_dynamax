{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j2SH7ks97hb"
   },
   "source": [
    "# Tracking Lorenz 63 using continuous-discrete Extended / Ensemble / Unscented Kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYrePRtV4RIK"
   },
   "source": [
    "This notebook demonstrates tracking chaotic dynamics from the Lorenz 63 system from partial and noisy observations sampled at regular time intervals.\n",
    "\n",
    "We generate dynamics according to the following stochastic differential equation:\n",
    "\\begin{align*}\n",
    "\\frac{d^2 x}{d t^2} &= a(y-x) + \\sigma w_x(t) \\\\\n",
    "\\frac{d^2 y}{d t^2} &= x(b-z) - y + \\sigma w_y(t) \\\\\n",
    "\\frac{d^2 z}{d t^2} &= xy - cz + \\sigma w_z(t),\n",
    "\\end{align*}\n",
    "where $a=10, b=28, c=8/3$ give rise to chaotic behavior, and we choose $\\sigma=0.1$ for light diffusion.\n",
    "\n",
    "We numerically approximate random path solutions to this SDE using Heun's method (i.e. improved Euler), as implemented in [Diffrax](https://docs.kidger.site/diffrax/api/solvers/sde_solvers/).\n",
    "\n",
    "\n",
    "We assume the observation model is\n",
    "\\begin{align*}\n",
    "y(t) &= x(t) + r(t) \\\\\n",
    "r(t) &\\sim N(0,R),\n",
    "\\end{align*}\n",
    "where we choose $R=I$ and sample at a uniform interval $\\Delta t \\in \\{0.01, 0.1\\}$.\n",
    "\n",
    "We approach the filtering problem using continuous-discrete Extended/Ensemble/Unscented Kalman Filters, and compare their performance. We see that the problem becomes more difficult when we have a slower sample rate and less knowledge of initial state distribution---in this setting, the Ensemble Kalman Filter shines and the Unscented Kalman Filter breaks at its first step (due to predicting a non-PSD state covariance).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that under regular sampling intervals, the typical discrete-time non-linear filtering paradigm is often sufficient. We do not compare to these for brevity. Instead, we simply demonstrate the performance of continuous-discrete methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLt4p8Tx4hWN"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%matplotlib inline\n",
    "sys.path.append(\"../../..\")\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import dynamax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jax import vmap\n",
    "from jax import lax\n",
    "from jaxtyping import Float, Array\n",
    "from typing import Callable, NamedTuple, Tuple, Optional, Union\n",
    "from jaxtyping import Array, Float, PyTree\n",
    "\n",
    "from dynamax.parameters import ParameterProperties\n",
    "\n",
    "# For pretty print of ndarrays\n",
    "jnp.set_printoptions(formatter={\"float_kind\": \"{:.2f}\".format})\n",
    "\n",
    "# import discrete-time filters\n",
    "from dynamax.nonlinear_gaussian_ssm import ParamsNLGSSM, UKFHyperParams\n",
    "from dynamax.nonlinear_gaussian_ssm import extended_kalman_smoother, unscented_kalman_smoother\n",
    "\n",
    "# import continuous-discrete nonlinear Gaussian SSM code\n",
    "# use custom src codebase\n",
    "from utils.plotting_utils import *\n",
    "from continuous_discrete_nonlinear_gaussian_ssm import ContDiscreteNonlinearGaussianSSM\n",
    "from continuous_discrete_nonlinear_gaussian_ssm import cdnlgssm_filter\n",
    "from continuous_discrete_nonlinear_gaussian_ssm import EnKFHyperParams, EKFHyperParams, UKFHyperParams\n",
    "\n",
    "# set up drift function\n",
    "from continuous_discrete_nonlinear_gaussian_ssm.models import (\n",
    "    LearnableFunction,\n",
    "    ConstantLearnableFunction,\n",
    "    LinearLearnableFunction,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lorenz(time_grid, x_tr, x_obs, x_est=None, est_type=\"\"):\n",
    "    plt.figure()\n",
    "    n_states = x_tr.shape[1]\n",
    "    for i in range(n_states):\n",
    "        plt.plot(time_grid, x_tr[:, i], color=f\"C{i}\", alpha=0.5, linewidth=4, label=f\"True State {i}\")\n",
    "\n",
    "    if x_est is not None:\n",
    "        for i in range(n_states):\n",
    "            plt.plot(\n",
    "                time_grid, x_est[:, i], \"--\", color=f\"C{i}\", linewidth=1.5, label=f\"{est_type} Estimated State {i}\"\n",
    "            )\n",
    "\n",
    "    n_obs = x_obs.shape[1]\n",
    "    for i in range(n_obs):\n",
    "        plt.plot(time_grid, x_obs[:, i], \"ok\", fillstyle=\"none\", ms=1.5, label=f\"Measurement {i}\")\n",
    "\n",
    "    plt.xlabel(\"Time $t$\")\n",
    "    # plt.ylabel(\"Pendulum angle $x_{1,k}$\")\n",
    "    # plt.xlim(0, 5)\n",
    "    # plt.ylim(-3, 5)\n",
    "    # plt.xticks(jnp.arange(0.5, 4.6, 0.5))\n",
    "    # plt.yticks(jnp.arange(-3, 5.1, 1))\n",
    "    # plt.gca().set_aspect(0.5)\n",
    "    plt.legend(loc=1, borderpad=0.5, handlelength=4, fancybox=False, edgecolor=\"k\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE\n",
    "def compute_rmse(y, y_est):\n",
    "    return jnp.sqrt(jnp.sum((y - y_est) ** 2) / len(y))\n",
    "\n",
    "\n",
    "# Compute RMSE of estimate and print comparison with\n",
    "# standard deviation of measurement noise\n",
    "def compute_and_print_rmse_comparison(y, y_est, R, est_type=\"\"):\n",
    "    rmse_est = compute_rmse(y, y_est)\n",
    "    print(f'{f\"The RMSE of the {est_type} estimate is\":<40}: {rmse_est:.2f}')\n",
    "    print(f'{\"The std of measurement noise is\":<40}: {jnp.sqrt(R):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main settings\n",
    "state_dim = 3\n",
    "emission_dim = 1\n",
    "\n",
    "\n",
    "class CustomDrift(LearnableFunction):\n",
    "    params: Union[Float[Array, \"state_dim\"], ParameterProperties]\n",
    "\n",
    "    def f(self, x, u=None, t=None):\n",
    "        foo = jnp.array(\n",
    "            [\n",
    "                self.params[0] * (x[1] - x[0]),\n",
    "                self.params[1] * x[0] - x[1] - x[0] * x[2],\n",
    "                -self.params[2] * x[2] + x[0] * x[1],\n",
    "            ]\n",
    "        )\n",
    "        return foo\n",
    "\n",
    "\n",
    "learnable_drift = CustomDrift(params=jnp.array([10.0, 28.0, 8 / 3]))\n",
    "learnable_emission = LinearLearnableFunction(params=jnp.array([[1.0, 0.0, 0.0]]))\n",
    "learnable_diffusion_cov = ConstantLearnableFunction(params=jnp.eye(state_dim))\n",
    "learnable_diffusion_coefficient = ConstantLearnableFunction(params=0.1 * jnp.eye(state_dim))\n",
    "learnable_emission_cov = ConstantLearnableFunction(params=jnp.eye(emission_dim))\n",
    "\n",
    "true_model = ContDiscreteNonlinearGaussianSSM(state_dim, emission_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33ISOI7QtWlP"
   },
   "source": [
    "## Fast sample rate and modest initial state covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code\n",
    "\n",
    "## HARD MODE\n",
    "# num_timesteps = 250\n",
    "# dt = 0.1\n",
    "# init_state_sd = 20\n",
    "\n",
    "## EASY MODE\n",
    "num_timesteps = 4000\n",
    "dt = 0.01\n",
    "init_state_sd = 10\n",
    "\n",
    "# set timesteps to be 400 timesteps at dt intervals\n",
    "t_emissions = jnp.arange(num_timesteps) * dt\n",
    "t_emissions = t_emissions.reshape(-1, 1)\n",
    "\n",
    "key = jr.PRNGKey(0)\n",
    "key, key_root = jr.split(key)\n",
    "true_params, param_props = true_model.initialize(\n",
    "    key,\n",
    "    initial_mean=jnp.array([0.0, 0.0, 0.0]),\n",
    "    initial_cov=jnp.eye(state_dim) * (init_state_sd**2),  # want to initialize at ~ initial mean\n",
    "    dynamics_drift=learnable_drift,\n",
    "    dynamics_diffusion_coefficient=learnable_diffusion_coefficient,\n",
    "    dynamics_diffusion_cov=learnable_diffusion_cov,\n",
    "    dynamics_approx_order=1.0,\n",
    "    emission_function=learnable_emission,\n",
    "    emission_cov=learnable_emission_cov,\n",
    ")\n",
    "\n",
    "key, key_root = jr.split(key)\n",
    "true_states, emissions = true_model.sample(true_params, key, num_timesteps, t_emissions)\n",
    "\n",
    "# Plot the true states and emissions\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(t_emissions, true_states[:, 0], color=\"C0\", label=\"state 1\")\n",
    "ax.plot(t_emissions, true_states[:, 1], color=\"C1\", label=\"state 2\")\n",
    "ax.plot(t_emissions, true_states[:, 2], color=\"C2\", label=\"state 3\")\n",
    "ax.plot(t_emissions, emissions[:, 0], \"x\", color=\"C0\", label=\"emission 1\")\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"data\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_title(\"Training Emissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Rx9XE5Af2sP"
   },
   "source": [
    "### Extended Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "icfpJJs3ik2i",
    "outputId": "a068fcc5-f67e-494a-ad21-c868bcefd80b"
   },
   "outputs": [],
   "source": [
    "ekf_filtered = cdnlgssm_filter(true_params, emissions, EKFHyperParams(), t_emissions)\n",
    "compute_and_print_rmse_comparison(true_states[:, -1], ekf_filtered.filtered_means[:,-1], 1, \"EKF\")\n",
    "plot_lorenz(t_emissions, true_states, emissions, x_est=ekf_filtered.filtered_means, est_type=\"EKF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enkf_filtered = cdnlgssm_filter(true_params, emissions, EnKFHyperParams(), t_emissions)\n",
    "compute_and_print_rmse_comparison(true_states[:, -1], enkf_filtered.filtered_means[:, -1], 1, \"EKF\")\n",
    "plot_lorenz(t_emissions, true_states, emissions, x_est=enkf_filtered.filtered_means, est_type=\"EnKF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscented Kalman Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukf_filtered = cdnlgssm_filter(true_params, emissions, UKFHyperParams(), t_emissions)\n",
    "compute_and_print_rmse_comparison(true_states[:, -1], ukf_filtered.filtered_means[:, -1], 1, \"UKF\")\n",
    "plot_lorenz(t_emissions, true_states, emissions, x_est=ukf_filtered.filtered_means, est_type=\"UKF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow sample rate and larger initial state covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code\n",
    "\n",
    "## HARD MODE\n",
    "num_timesteps = 400\n",
    "dt = 0.1\n",
    "init_state_sd = 20\n",
    "\n",
    "## EASY MODE\n",
    "# num_timesteps = 4000\n",
    "# dt = 0.01\n",
    "# init_state_sd = 10\n",
    "\n",
    "# set timesteps to be 400 timesteps at dt intervals\n",
    "t_emissions = jnp.arange(num_timesteps) * dt\n",
    "t_emissions = t_emissions.reshape(-1, 1)\n",
    "\n",
    "key = jr.PRNGKey(0)\n",
    "key, key_root = jr.split(key)\n",
    "true_params, param_props = true_model.initialize(\n",
    "    key,\n",
    "    initial_mean=jnp.array([0.0, 0.0, 0.0]),\n",
    "    initial_cov=jnp.eye(state_dim) * (init_state_sd**2),  # want to initialize at ~ initial mean\n",
    "    dynamics_drift=learnable_drift,\n",
    "    dynamics_diffusion_coefficient=learnable_diffusion_coefficient,\n",
    "    dynamics_diffusion_cov=learnable_diffusion_cov,\n",
    "    dynamics_approx_order=1.0,\n",
    "    emission_function=learnable_emission,\n",
    "    emission_cov=learnable_emission_cov,\n",
    ")\n",
    "\n",
    "key, key_root = jr.split(key)\n",
    "true_states, emissions = true_model.sample(true_params, key, num_timesteps, t_emissions)\n",
    "\n",
    "# Plot the true states and emissions\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(t_emissions, true_states[:, 0], color=\"C0\", label=\"state 1\")\n",
    "ax.plot(t_emissions, true_states[:, 1], color=\"C1\", label=\"state 2\")\n",
    "ax.plot(t_emissions, true_states[:, 2], color=\"C2\", label=\"state 3\")\n",
    "ax.plot(t_emissions, emissions[:, 0], \"x\", color=\"C0\", label=\"emission 1\")\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"data\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_title(\"Training Emissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekf_filtered = cdnlgssm_filter(true_params, emissions, EKFHyperParams(), t_emissions)\n",
    "compute_and_print_rmse_comparison(true_states[:, -1], ekf_filtered.filtered_means[:, -1], 1, \"EKF\")\n",
    "plot_lorenz(t_emissions, true_states, emissions, x_est=ekf_filtered.filtered_means, est_type=\"EKF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enkf_filtered = cdnlgssm_filter(true_params, emissions, EnKFHyperParams(), t_emissions)\n",
    "compute_and_print_rmse_comparison(true_states[:, -1], enkf_filtered.filtered_means[:, -1], 1, \"EnKF\")\n",
    "plot_lorenz(t_emissions, true_states, emissions, x_est=enkf_filtered.filtered_means, est_type=\"EnKF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscented Kalman Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukf_filtered = cdnlgssm_filter(true_params, emissions, UKFHyperParams(), t_emissions)\n",
    "compute_and_print_rmse_comparison(true_states[:, -1], ukf_filtered.filtered_means[:, -1], 1, \"UKF\")\n",
    "plot_lorenz(t_emissions, true_states, emissions, x_est=ukf_filtered.filtered_means, est_type=\"UKF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unclear why UKF is failing here---I've pinpointed the issue to the first call of _predict in the UKF. More specifically, the first step of an Euler approximation yields a dP/dt that is very non-psd. This comes from the deterministic term given by (f_x_t.T @ W @ X_t) + (f_x_t.T @ W @ X_t).T."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "pendulum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "92401d49bd83f70620e540b668b7091047c2ca041ed5ff6cc3954130de9aa1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
