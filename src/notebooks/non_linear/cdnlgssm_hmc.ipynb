{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian parameter estimation for an LG-SSM using HMC\n",
    "\n",
    "We show how to use the [blackjax](https://github.com/blackjax-devs/blackjax) libray to compute the parameter posterior $p(\\theta|y(1:T))$\n",
    "for an LGSSM model. We use the Kalman filter to compute the marginal likelihood, $p(y(1:T) | \\theta) = \\int_{z(1:T)} p(z(1:T), y(1:T)|\\theta)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%matplotlib inline\n",
    "sys.path.append(\"../../..\")\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import dynamax\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from jax import vmap\n",
    "import jax.random as jr\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# use custom src codebase\n",
    "from utils.plotting_utils import *\n",
    "\n",
    "# from utils.utils import monotonically_increasing\n",
    "from continuous_discrete_nonlinear_gaussian_ssm import ContDiscreteNonlinearGaussianSSM\n",
    "from continuous_discrete_nonlinear_gaussian_ssm.models import (\n",
    "    LearnableFunction,\n",
    "    ConstantLearnableFunction,\n",
    "    LinearLearnableFunction,\n",
    ")\n",
    "\n",
    "import blackjax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random as  jr\n",
    "from jax import numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from itertools import count\n",
    "\n",
    "from dynamax.linear_gaussian_ssm import LinearGaussianSSM\n",
    "from dynamax.parameters import log_det_jac_constrain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate synthetic data from true model\n",
    "state_dim = 2\n",
    "emission_dim = 10\n",
    "num_timesteps = 200\n",
    "t_emissions = jnp.arange(num_timesteps)[:, None]\n",
    "keys = map(jr.PRNGKey, count())\n",
    "\n",
    "# Create a model with oscillatory dynamics\n",
    "drift_weights = jnp.array([[0, -1], [1, 0]])\n",
    "\n",
    "true_model = ContDiscreteNonlinearGaussianSSM(state_dim, emission_dim)\n",
    "true_params, _ = true_model.initialize(\n",
    "    next(keys),\n",
    "    dynamics_drift=LinearLearnableFunction(params=drift_weights),\n",
    "    dynamics_diffusion_coefficient=ConstantLearnableFunction(params=0.01*jnp.eye(state_dim)),\n",
    "    dynamics_diffusion_cov=ConstantLearnableFunction(params=jnp.eye(state_dim)),\n",
    ")\n",
    "true_states, emissions = true_model.sample(true_params, next(keys), num_timesteps, t_emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(emissions, smoothed_emissions, smoothed_emissions_std):\n",
    "    # all arrays are (T, E) dimensional, T=ntime, E=emission_dim\n",
    "    spc = 3\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(emission_dim):\n",
    "        plt.plot(emissions[:, i] + spc * i, \"--k\", label=\"observed\" if i == 0 else None)\n",
    "        ln = plt.plot(smoothed_emissions[:, i] + spc * i,\n",
    "                    label=\"smoothed\" if i == 0 else None)[0]\n",
    "        plt.fill_between(\n",
    "            jnp.arange(num_timesteps),\n",
    "            spc * i + smoothed_emissions[:, i] - 2 * smoothed_emissions_std[:, i],\n",
    "            spc * i + smoothed_emissions[:, i] + 2 * smoothed_emissions_std[:, i],\n",
    "            color=ln.get_color(),\n",
    "            alpha=0.25,\n",
    "        )\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.xlim(0, num_timesteps - 1)\n",
    "    plt.ylabel(\"true and predicted emissions\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(emissions, emissions, 0.1*jnp.ones_like(emissions)) # fake posterior variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline method: use SGD to compute MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize parameters by fitting SGD algorithm\n",
    "from continuous_discrete_nonlinear_gaussian_ssm import cdnlgssm_filter\n",
    "from continuous_discrete_nonlinear_gaussian_ssm import EKFHyperParams\n",
    "from continuous_discrete_nonlinear_gaussian_ssm.models import LearnableFunction,ConstantLearnableFunction,LinearLearnableFunction\n",
    "num_epochs = 4000\n",
    "\n",
    "filter_hyperparams = EKFHyperParams()\n",
    "test_model = ContDiscreteNonlinearGaussianSSM(state_dim, emission_dim)\n",
    "initial_params, param_props = test_model.initialize(next(keys))\n",
    "# fitted_params, marginal_lls = test_model.fit_em(initial_params, param_props, emissions, num_iters=num_iters)\n",
    "fitted_params, marginal_lls = test_model.fit_sgd(\n",
    "    initial_params,\n",
    "    param_props,\n",
    "    emissions,\n",
    "    filter_hyperparams=filter_hyperparams,\n",
    "    t_emissions=t_emissions,\n",
    "    num_epochs=num_epochs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fitted params\n",
    "fitted_C = fitted_params.emissions.emission_function.params\n",
    "# fitted_d = fitted_params.emissions.bias\n",
    "fitted_d = 0\n",
    "fitted_R = fitted_params.emissions.emission_cov.params\n",
    "\n",
    "# Compute predicted emissions\n",
    "filtered_posterior = cdnlgssm_filter(\n",
    "    fitted_params, emissions=emissions, hyperparams=filter_hyperparams, t_emissions=t_emissions\n",
    ")\n",
    "filtered_emissions_mean = filtered_posterior.filtered_means @ fitted_C.T + fitted_d\n",
    "filtered_emissions_cov = fitted_C @ filtered_posterior.filtered_covariances @ fitted_C.T + fitted_R\n",
    "filtered_emissions_std = jnp.sqrt(jnp.array([filtered_emissions_cov[:, i, i] for i in range(emission_dim)])).T  # (T,E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the marginal lls over iterations for SGD\n",
    "plt.plot(marginal_lls)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"marginal log likelihood\")\n",
    "# plt.autoscale(enable=True, axis=\"x\", tight=True)\n",
    "plt.title(\"Marginal log likelihood over iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([emissions.shape, filtered_emissions_mean.shape, filtered_emissions_std.shape])\n",
    "plot_results(emissions, filtered_emissions_mean, filtered_emissions_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement HMC wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamax.parameters import to_unconstrained, from_unconstrained\n",
    "from dynamax.utils.utils import pytree_stack, ensure_array_has_batch_dim\n",
    "from functools import partial\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "\n",
    "\n",
    "def fit_hmc(\n",
    "    model,\n",
    "    initial_params,\n",
    "    props,\n",
    "    key,\n",
    "    num_samples,\n",
    "    emissions,\n",
    "    filter_hyperparams,\n",
    "    inputs=None,\n",
    "    warmup_steps=100,\n",
    "    num_integration_steps=30,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"Sample parameters of the model using HMC.\"\"\"\n",
    "    # Make sure the emissions and inputs have batch dimensions\n",
    "    batch_emissions = ensure_array_has_batch_dim(emissions, model.emission_shape)\n",
    "    batch_inputs = ensure_array_has_batch_dim(inputs, model.inputs_shape)\n",
    "\n",
    "    initial_unc_params = to_unconstrained(initial_params, props)\n",
    "\n",
    "    # The log likelihood that the HMC samples from\n",
    "    def _logprob(unc_params):\n",
    "        params = from_unconstrained(unc_params, props)\n",
    "        batch_lls = vmap(partial(model.marginal_log_prob, params, filter_hyperparams))(batch_emissions, batch_inputs)\n",
    "        lp = model.log_prior(params) + batch_lls.sum()\n",
    "        lp += log_det_jac_constrain(params, props)\n",
    "        return lp\n",
    "\n",
    "    # Initialize the HMC sampler using window_adaptation\n",
    "    warmup = blackjax.window_adaptation(blackjax.hmc,\n",
    "                                        _logprob,\n",
    "                                        num_steps=warmup_steps,\n",
    "                                        num_integration_steps=num_integration_steps,\n",
    "                                        progress_bar=verbose)\n",
    "    init_key, key = jr.split(key)\n",
    "    hmc_initial_state, hmc_kernel, _ = warmup.run(init_key, initial_unc_params)\n",
    "\n",
    "    @jit\n",
    "    def hmc_step(hmc_state, step_key):\n",
    "        next_hmc_state, _ = hmc_kernel(step_key, hmc_state)\n",
    "        params = from_unconstrained(hmc_state.position, props)\n",
    "        return next_hmc_state, params\n",
    "\n",
    "    # Start sampling\n",
    "    log_probs = []\n",
    "    samples = []\n",
    "    hmc_state = hmc_initial_state\n",
    "    pbar = progress_bar(range(num_samples)) if verbose else range(num_samples)\n",
    "    for _ in pbar:\n",
    "        step_key, key = jr.split(key)\n",
    "        hmc_state, params = hmc_step(hmc_state, step_key)\n",
    "        log_probs.append(-hmc_state.potential_energy)\n",
    "        samples.append(params)\n",
    "\n",
    "    # Combine the samples into a single pytree\n",
    "    return pytree_stack(samples), jnp.array(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def filter_emission(params):\n",
    "    C = params.emissions.emission_function.params\n",
    "    # d = params.emissions.bias\n",
    "    d = 0\n",
    "    filtered_posterior = cdnlgssm_filter(\n",
    "        params, emissions=emissions, hyperparams=filter_hyperparams, t_emissions=t_emissions\n",
    "    )\n",
    "\n",
    "    return filtered_posterior.filtered_means @ C.T + d    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_param_distributions(samples, true, sgd, name='', burn_in_frac=0.5):\n",
    "    \"\"\"\n",
    "    Plots N_params horizontal box plots for the given N_params x N_samples matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - samples: N_params x N_samples matrix of parameter samples.\n",
    "    - true: N_params array of true parameter values.\n",
    "    - sgd: N_params array of SGD estimates.\n",
    "    - name: Name of the parameter set.\n",
    "    - burn_in_frac: Fraction of samples to discard as burn-in.\n",
    "\n",
    "    Returns:\n",
    "    - A matplotlib figure with N_params horizontal box plots.\n",
    "    \"\"\"\n",
    "    N_params = samples.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(10, N_params * 2))  # Adjust figure size based on number of parameters\n",
    "\n",
    "    # apply burn-in\n",
    "    burn_in = int(burn_in_frac * samples.shape[1])\n",
    "    samples = samples[:, burn_in:]\n",
    "    \n",
    "    # Create box plots\n",
    "    ax.boxplot(samples, vert=False, patch_artist=True)\n",
    "\n",
    "    # Set the y-axis labels to show parameter indices\n",
    "    ax.set_yticks(range(1, N_params + 1))\n",
    "    ax.set_yticklabels([\"Parameter {}\".format(i + 1) for i in range(N_params)])\n",
    "\n",
    "    # Plot ground truth and estimates\n",
    "    ax.scatter(sgd, range(1, N_params + 1), color=\"magenta\", marker=\"o\", s=100, label=\"SGD Estimate\", zorder=3)\n",
    "    ax.scatter(true, range(1, N_params + 1), color=\"red\", marker=\"x\", s=100, label=\"Ground Truth\", zorder=4)\n",
    "\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Parameters\")\n",
    "    plt.title(\"{} Parameter Distributions\".format(name))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_all(param_samples, burn_in_frac=0.5):\n",
    "    \"\"\"\n",
    "    Plots the posterior distributions of all parameters.\n",
    "    Burn-in is removed from the samples.\n",
    "    \"\"\"\n",
    "    plot_param_distributions(\n",
    "        param_samples.initial.mean.T, true_params.initial.mean, fitted_params.initial.mean, name=\"Initial mean\",\n",
    "        burn_in_frac=burn_in_frac\n",
    "    )\n",
    "    plot_param_distributions(\n",
    "        param_samples.initial.cov.reshape(-1, param_samples.initial.cov.shape[0]),\n",
    "        true_params.initial.cov.flatten(),\n",
    "        fitted_params.initial.cov.flatten(),\n",
    "        name=\"Initial cov\",\n",
    "        burn_in_frac=burn_in_frac,\n",
    "    )\n",
    "    plot_param_distributions(\n",
    "        param_samples.dynamics.drift.params.reshape(-1, param_samples.dynamics.drift.params.shape[0]),\n",
    "        true_params.dynamics.drift.params,\n",
    "        fitted_params.dynamics.drift.params,\n",
    "        name=\"Dynamics drift\",\n",
    "        burn_in_frac=burn_in_frac,\n",
    "    )\n",
    "    plot_param_distributions(\n",
    "        param_samples.dynamics.diffusion_cov.params.reshape(-1, param_samples.dynamics.diffusion_cov.params.shape[0]),\n",
    "        true_params.dynamics.diffusion_cov.params.flatten(),\n",
    "        fitted_params.dynamics.diffusion_cov.params.flatten(),\n",
    "        name=\"Dynamics diffusion cov\",\n",
    "        burn_in_frac=burn_in_frac,\n",
    "    )\n",
    "    plot_param_distributions(\n",
    "        param_samples.dynamics.diffusion_coefficient.params.reshape(\n",
    "            -1, param_samples.dynamics.diffusion_coefficient.params.shape[0]\n",
    "        ),\n",
    "        true_params.dynamics.diffusion_coefficient.params.flatten(),\n",
    "        fitted_params.dynamics.diffusion_coefficient.params.flatten(),\n",
    "        name=\"Dynamics diffusion coefficient\",\n",
    "        burn_in_frac=burn_in_frac,\n",
    "    )\n",
    "    plot_param_distributions(\n",
    "        param_samples.emissions.emission_function.params.reshape(\n",
    "            -1, param_samples.emissions.emission_function.params.shape[0]\n",
    "        ),\n",
    "        true_params.emissions.emission_function.params.flatten(),\n",
    "        fitted_params.emissions.emission_function.params.flatten(),\n",
    "        name=\"Emissions function\",\n",
    "        burn_in_frac=burn_in_frac,\n",
    "    )\n",
    "    plot_param_distributions(\n",
    "        param_samples.emissions.emission_cov.params.reshape(-1, param_samples.emissions.emission_cov.params.shape[0]),\n",
    "        true_params.emissions.emission_cov.params.flatten(),\n",
    "        fitted_params.emissions.emission_cov.params.flatten(),\n",
    "        name=\"Emissions cov\",\n",
    "        burn_in_frac=burn_in_frac,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, run HMC initialized using the SGD-fitted parameters\n",
    "sample_size = 500\n",
    "param_samples, lps = fit_hmc(\n",
    "    test_model,\n",
    "    fitted_params, #initial_params,\n",
    "    param_props,\n",
    "    next(keys),\n",
    "    sample_size,\n",
    "    emissions,\n",
    "    filter_hyperparams=filter_hyperparams,\n",
    "    num_integration_steps=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lps)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.xlabel(\"log probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute eigenvalues of param_samples.dynamics.drift.params across samples using vmap\n",
    "\n",
    "eigvals = vmap(jnp.linalg.eigvals)(param_samples.dynamics.drift.params)\n",
    "\n",
    "# plot the complex part of the eigenvalues\n",
    "plt.plot(eigvals.real[:, 0], label=\"first Real\")\n",
    "plt.plot(eigvals.imag[:, 0], label=\"first Imag\")\n",
    "plt.plot(eigvals.real[:, 1], label=\"second Real\")\n",
    "plt.plot(eigvals.imag[:, 1], label=\"second Imag\")\n",
    "plt.plot(param_samples.dynamics.drift.params[:, 1, 0], label=\"First off-diagonal\")\n",
    "plt.plot(param_samples.dynamics.drift.params[:, 0, 1], label=\"Second off-diagonal\")\n",
    "plt.legend()\n",
    "plt.title(\"Eigenvalues of the drift matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_emissions = vmap(filter_emission)(param_samples)\n",
    "filtered_emissions_mean = filtered_emissions.mean(axis=0)\n",
    "filtered_emissions_std = jnp.std(filtered_emissions, axis=0)\n",
    "\n",
    "# note that this shows a distribution of filtered means\n",
    "# Unlike earlier plots, it does not show the filtered covariances, \n",
    "# which would add an appearance of greater uncertainty.\n",
    "print([emissions.shape, filtered_emissions.shape, filtered_emissions_mean.shape, filtered_emissions_std.shape])\n",
    "plot_results(emissions, filtered_emissions_mean, filtered_emissions_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_states[0], filtered_posterior.filtered_means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(param_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
