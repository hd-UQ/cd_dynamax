{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameter estimation for an irregularly-sampled, continuous-discrete (non-linear) dynamical system\n",
    "\n",
    "We show how to use cd-dynamax to estimate the parameters of a continuous-discrete (non-linear) dynamical system\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import sys\n",
    "from itertools import count\n",
    "\n",
    "# Import jax and utils\n",
    "from jax import numpy as jnp\n",
    "from jax import vmap\n",
    "import jax.random as jr\n",
    "from jax import jit, vmap\n",
    "\n",
    "# Additional, custom codebase\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "# Our own custom src codebase\n",
    "# continuous-discrete nonlinear Gaussian SSM codebase\n",
    "from utils.plotting_utils import *\n",
    "# CD-Nonlinear Gaussian models\n",
    "from continuous_discrete_nonlinear_gaussian_ssm import ContDiscreteNonlinearGaussianSSM\n",
    "from continuous_discrete_nonlinear_gaussian_ssm.models import *\n",
    "\n",
    "# Useful utility functions\n",
    "from simulation_utils import *\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# Our own custom plotting codebase\n",
    "from utils.plotting_utils import *\n",
    "from lorenz_plotting import *\n",
    "from parameter_learning_plotting import *\n",
    "# Feel free to change the default figure size\n",
    "#matplotlib.rcParams['figure.figsize'] = [16, 9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate data from a Lorenz 63 system, from dynamics with the following stochastic differential equations:\n",
    "\\begin{align*}\n",
    "\\frac{d x}{d t} &= a(y-x) + \\sigma w_x(t) \\\\\n",
    "\\frac{d y}{d t} &= x(b-z) - y + \\sigma w_y(t) \\\\\n",
    "\\frac{d z}{d t} &= xy - cz + \\sigma w_z(t),\n",
    "\\end{align*}\n",
    "\n",
    "With parameters $a=10, b=28, c=8/3$, the system gives rise to chaotic behavior, and we choose $\\sigma=0.1$ for light diffusion.\n",
    "\n",
    "To generate data, we numerically approximate random path solutions to this SDE using Heun's method (i.e. improved Euler), as implemented in [Diffrax](https://docs.kidger.site/diffrax/api/solvers/sde_solvers/).\n",
    "\n",
    "\n",
    "We assume the observation model is\n",
    "\\begin{align*}\n",
    "y(t) &= H x(t) + r(t) \\\\\n",
    "r(t) &\\sim N(0,R),\n",
    "\\end{align*}\n",
    "where we choose $R=I$. \n",
    "\n",
    "Namely, with H=I, we have full observability, with noisy observations, sampled at irregular time intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True, data-generating model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main settings\n",
    "state_dim = 3\n",
    "emission_dim = 3\n",
    "\n",
    "# Define a custom drift model, inherited from LearnableFunction\n",
    "class lorenz63_drift(LearnableFunction):\n",
    "    params: Union[Float[Array, \"state_dim\"], ParameterProperties]\n",
    "\n",
    "    def f(self, x, u=None, t=None):\n",
    "        foo = jnp.array(\n",
    "            [\n",
    "                self.params[0] * (x[1] - x[0]),\n",
    "                self.params[1] * x[0] - x[1] - x[0] * x[2],\n",
    "                -self.params[2] * x[2] + x[0] * x[1],\n",
    "            ]\n",
    "        )\n",
    "        return foo\n",
    "\n",
    "# Define the true parameters of the drift function\n",
    "true_l63_drift_params = jnp.array([10.0, 28.0, 8 / 3])\n",
    "# And the corresponding Lorenz 63 system\n",
    "true_drift = {\n",
    "    \"params\": lorenz63_drift(\n",
    "        params=true_l63_drift_params\n",
    "    ),\n",
    "    \"props\": lorenz63_drift(\n",
    "        params=ParameterProperties()\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the true parameters of the diffusion function\n",
    "true_diffusion_cov = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=jnp.eye(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(\n",
    "        params=ParameterProperties(\n",
    "            constrainer=RealToPSDBijector()\n",
    "        )\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the true parameters of the diffusion function\n",
    "true_diffusion_coefficient_param = 0.1\n",
    "true_diffusion_coefficient = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=true_diffusion_coefficient_param * jnp.eye(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(\n",
    "        params=ParameterProperties()\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the true parameters of the emission function\n",
    "# Full observability\n",
    "H=jnp.eye(emission_dim,state_dim)\n",
    "true_emission = {\n",
    "    \"params\": LearnableLinear(\n",
    "        weights=H,\n",
    "        bias=jnp.zeros(emission_dim)\n",
    "    ),\n",
    "    \"props\": LearnableLinear(\n",
    "        weights=ParameterProperties(),\n",
    "        bias=ParameterProperties()\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the true parameters of the emission covariance\n",
    "R=jnp.eye(emission_dim)\n",
    "true_emission_cov = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=R\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(\n",
    "        params=ParameterProperties(\n",
    "            constrainer=RealToPSDBijector()\n",
    "        )\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the true initial mean and covariance\n",
    "true_initial_mean = {\n",
    "    \"params\": LearnableVector(\n",
    "        params=jnp.zeros(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableVector(\n",
    "        params=ParameterProperties()\n",
    "    ),\n",
    "}\n",
    "\n",
    "true_initial_cov_param = 10.0\n",
    "true_initial_cov = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=true_initial_cov_param*jnp.eye(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(\n",
    "        params=ParameterProperties(\n",
    "            constrainer=RealToPSDBijector()\n",
    "        )\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Concatenate all parameters in dictionary, for later easy use\n",
    "all_true_params = {\n",
    "    'initial_mean': true_initial_mean,\n",
    "    'initial_cov': true_initial_cov,\n",
    "    'dynamics_drift': true_drift,\n",
    "    'dynamics_diffusion_coefficient': true_diffusion_coefficient,\n",
    "    'dynamics_diffusion_cov': true_diffusion_cov,\n",
    "    'dynamics_approx_order': 2., # Check on this later\n",
    "    'emission_function': true_emission,\n",
    "    'emission_cov': true_emission_cov,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seed for simulation\n",
    "keys = map(jr.PRNGKey, count())\n",
    "\n",
    "# Simulation parameters\n",
    "T_filter = 40\n",
    "T_total = 50\n",
    "num_timesteps_total = int(T_total*100)\n",
    "\n",
    "# Generate time points for measurements, filtering and forecasting\n",
    "# We will generate different train and test sets\n",
    "\n",
    "## Train set\n",
    "t_emissions_train, t_filter_train, t_forecast_train, \\\n",
    "    num_timesteps_train, num_timesteps_filter_train, num_timesteps_forecast_train= \\\n",
    "    generate_irregular_t_emissions(\n",
    "        T_total=T_total,\n",
    "        num_timesteps=num_timesteps_total,\n",
    "        T_filter=T_filter,\n",
    "        key=next(keys)\n",
    "    )\n",
    "\n",
    "## Test set\n",
    "t_emissions_test, t_filter_test, t_forecast_test, \\\n",
    "    num_timesteps_test, num_timesteps_filter_test, num_timesteps_forecast_test= \\\n",
    "    generate_irregular_t_emissions(\n",
    "        T_total=T_total,\n",
    "        num_timesteps=num_timesteps_total,\n",
    "        T_filter=T_filter,\n",
    "        key=next(keys)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation: object instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CD-NLGSSM model\n",
    "true_model = ContDiscreteNonlinearGaussianSSM(state_dim, emission_dim)\n",
    "true_params, _ = true_model.initialize(\n",
    "    next(keys),\n",
    "    **all_true_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate data: sample from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample true states and emissions from defined true model.\n",
    "# Using transition_type=\"path\" to solve the dynamics SDE.\n",
    "\n",
    "## Train set\n",
    "true_states_train, true_emissions_train = true_model.sample(\n",
    "    true_params,\n",
    "    next(keys),\n",
    "    num_timesteps_train,\n",
    "    t_emissions_train,\n",
    "    transition_type=\"path\" # uses the Euler-Maruyama method\n",
    ")\n",
    "\n",
    "## Test set\n",
    "true_states_test, true_emissions_test = true_model.sample(\n",
    "    true_params,\n",
    "    next(keys),\n",
    "    num_timesteps_test,\n",
    "    t_emissions_test,\n",
    "    transition_type=\"path\" # uses the Euler-Maruyama method\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the training data\n",
    "plot_advanced2(\n",
    "    time_grid_all=t_emissions_train,\n",
    "    true_states=true_states_train,\n",
    "    true_emissions_noisy=true_emissions_train,\n",
    "    emission_function=true_params.emissions.emission_function\n",
    ")\n",
    "\n",
    "# Plot the filtering training data\n",
    "plot_advanced2(\n",
    "    time_grid_all=t_emissions_train,\n",
    "    true_states=true_states_train,\n",
    "    true_emissions_noisy=true_emissions_train,\n",
    "    emission_function=true_params.emissions.emission_function,\n",
    "    t_start=0,\n",
    "    t_end=T_filter\n",
    ")\n",
    "\n",
    "# Plot the forecasting training data\n",
    "plot_advanced2(\n",
    "    time_grid_all=t_emissions_train,\n",
    "    true_states=true_states_train,\n",
    "    true_emissions_noisy=true_emissions_train,\n",
    "    emission_function=true_params.emissions.emission_function,\n",
    "    t_start=T_filter,\n",
    "    t_end=T_total\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start by defining a new model that is learnable\n",
    "\n",
    "- We want to learn a model that might or might not be within the same function class of the data-generating mechanism\n",
    "\n",
    "- The learnable model will be a ContDiscreteNonlinearGaussianSSM\n",
    "\n",
    "- Here, we define the same model family as the data-generating model\n",
    "    - i.e., the model family class is the same\n",
    "\n",
    "- However:\n",
    "    - the dynamics drift function will not-initialized to true values, and will be learnable\n",
    "    - The rest of the model components will NOT be learnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE hint\n",
    "\n",
    "- By default, all ParamProperties are set to trainable=True\n",
    "\n",
    "- So, make sure you EXPLICITLY set trainable=False for all parameters you DO NOT want to learn/infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main settings\n",
    "state_dim = 3\n",
    "emission_dim = 3\n",
    "\n",
    "# The only learnable parameters are those in the learnable_drift\n",
    "# An initial guess that is close to the true parameters\n",
    "perturbation = jr.normal(next(keys), (len(true_l63_drift_params),))\n",
    "drift_parameter_guess = true_l63_drift_params * (1.0 + 0.5 * perturbation)\n",
    "\n",
    "# Define the learnable drift model, with initial guess\n",
    "learnable_drift = {\n",
    "    \"params\": lorenz63_drift(params=drift_parameter_guess),\n",
    "    \"props\": lorenz63_drift(params=ParameterProperties()),\n",
    "}\n",
    "\n",
    "## All parameters below are NOT learnable\n",
    "learnable_diffusion_cov = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=jnp.eye(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(\n",
    "        params=ParameterProperties(\n",
    "            trainable=False,\n",
    "            constrainer=RealToPSDBijector()\n",
    "        )\n",
    "    ),\n",
    "}\n",
    "\n",
    "# The diffusion coefficient is fixed to non-learnable identity\n",
    "learnable_diffusion_coefficient = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=true_diffusion_coefficient_param * jnp.eye(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(\n",
    "        params=ParameterProperties(trainable=False)\n",
    "    ),\n",
    "}\n",
    "\n",
    "# The emission function is fixed to non-learnable identity\n",
    "learnable_emission = {\n",
    "    \"params\": LearnableLinear(\n",
    "        weights=H,\n",
    "        bias=jnp.zeros(emission_dim)\n",
    "    ),\n",
    "    \"props\": LearnableLinear(\n",
    "        weights=ParameterProperties(trainable=False),\n",
    "        bias=ParameterProperties(trainable=False)\n",
    "    ),\n",
    "}\n",
    "\n",
    "# The emission covariance is fixed to non-learnable identity\n",
    "learnable_emission_cov = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=R\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(\n",
    "        params=ParameterProperties(\n",
    "            trainable=False,\n",
    "            constrainer=RealToPSDBijector()\n",
    "        )\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the initial mean and covariance\n",
    "learnable_initial_mean = {\n",
    "    \"params\": LearnableVector(\n",
    "        params=jnp.zeros(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableVector(\n",
    "        params=ParameterProperties(trainable=False)\n",
    "    ),\n",
    "}\n",
    "\n",
    "learnable_initial_cov = {\n",
    "    \"params\": LearnableMatrix(\n",
    "        params=10.0 * jnp.eye(state_dim)\n",
    "    ),\n",
    "    \"props\": LearnableMatrix(params=ParameterProperties(trainable=False, constrainer=RealToPSDBijector())),\n",
    "}\n",
    "\n",
    "# Concatenate all parameters in dictionary, for later easy use\n",
    "all_learnable_params = {\n",
    "    \"initial_mean\": learnable_initial_mean,\n",
    "    \"initial_cov\": learnable_initial_cov,\n",
    "    \"dynamics_drift\": learnable_drift,\n",
    "    \"dynamics_diffusion_coefficient\": learnable_diffusion_coefficient,\n",
    "    \"dynamics_diffusion_cov\": learnable_diffusion_cov,\n",
    "    \"dynamics_approx_order\": 2.,  # Check on this later\n",
    "    \"emission_function\": learnable_emission,\n",
    "    \"emission_cov\": learnable_emission_cov,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define, instantiate and initialize the learnable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CD-NLGSSM model\n",
    "learnable_model = ContDiscreteNonlinearGaussianSSM(state_dim, emission_dim)\n",
    "initial_learnable_params, learnable_props = learnable_model.initialize(\n",
    "    next(keys),\n",
    "    **all_learnable_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian parameter estimation: Maximum A-Posteriori (MAP) estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian parameter estimation for an irregularly-sampled, continuous-discrete (non-linear) Gaussian dynamical system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMC w/ autodifferentiable filtering\n",
    "\n",
    "We show how to use the [blackjax](https://github.com/blackjax-devs/blackjax) libray to compute the HMC-based parameter posterior $p(\\theta|y(1:T))$ for a nonlinear dynamical model.\n",
    "\n",
    "    - TODO: Showcase how to use NUTS\n",
    "\n",
    "We use the Extended Kalman filter to compute the marginal likelihood, $p(y(1:T) | \\theta) = \\int_{z(1:T)} p(z(1:T), y(1:T)|\\theta)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model MAP learning, based on HMC\n",
    "- We will use Extended Kalman Filtering to compute the marginal log probability, for SGD to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: EKF\n",
    "hmc_filter_hyperparams = EKFHyperParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMC hyperparameters and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMC hyperparameters (100/100/15 runs in ~15minutes. For faster run, reduce these numbers)\n",
    "hmc_N_samples = 100\n",
    "hmc_warmup = 100\n",
    "hmc_integration_steps=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMC is initialized at random parameters\n",
    "# Run\n",
    "hmc_param_samples, hmc_marginal_log_prob = learnable_model.fit_hmc(\n",
    "    initial_learnable_params,\n",
    "    learnable_props,\n",
    "    true_emissions_train,\n",
    "    t_emissions=t_emissions_train,\n",
    "    filter_hyperparams=hmc_filter_hyperparams,\n",
    "    num_samples=hmc_N_samples,\n",
    "    warmup_steps=hmc_warmup,\n",
    "    num_integration_steps=hmc_integration_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize learning: marginal log-likelihood evolution over MCMC iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mll_learning_curve(\n",
    "    true_model,\n",
    "    true_params,\n",
    "    true_emissions_train,\n",
    "    t_emissions_train,\n",
    "    hmc_marginal_log_prob,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filter and forecast time points\n",
    "T0 = 5 # Ignore initial transient\n",
    "T_filter_end = 25 # End of filtering\n",
    "T_forecast_end = 45 # End of forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmap over filter and forecast function\n",
    "(hmc_filtered_train, hmc_forecasted_train, \\\n",
    "    hmc_start_idx_filter, hmc_stop_idx_filter, \\\n",
    "    hmc_start_idx_forecast, hmc_stop_idx_forecast\n",
    "    ) = vmap(\n",
    "        filter_and_forecast,\n",
    "        in_axes=(0, None, None, None, None, None, None) # only over param_samples\n",
    "    )(\n",
    "        hmc_param_samples,\n",
    "        hmc_filter_hyperparams,\n",
    "        t_emissions_train,\n",
    "        true_emissions_train,\n",
    "        T0,\n",
    "        T_filter_end,\n",
    "        T_forecast_end\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmap over cdnlssm emissions function, to get the filtered emissions\n",
    "# based on the vmapped params, filtered state means and filtered state covariances\n",
    "(hmc_filtered_train_emissions_mean, hmc_filtered_train_emissions_covariance) = vmap(\n",
    "        cdnlgssm_emissions,\n",
    "        in_axes=(0, None, 0, 0, None, None, None) # vmap over axis 0 of params, state_means and state_covs\n",
    "    )(\n",
    "        hmc_param_samples,\n",
    "        t_emissions_train[hmc_start_idx_filter[0]:hmc_stop_idx_filter[0]],\n",
    "        hmc_filtered_train.filtered_means,\n",
    "        hmc_filtered_train.filtered_covariances,\n",
    "        None,\n",
    "        EKFHyperParams(),\n",
    "        next(keys),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmap over cdnlssm emissions function, to get the forecasted emissions\n",
    "# based on the vmapped params, forecasted state means and state covariances\n",
    "(hmc_forecasted_train_emissions_mean, hmc_forecasted_train_emissions_covariance) = vmap(\n",
    "        cdnlgssm_emissions,\n",
    "        in_axes=(0, None, 0, 0, None, None, None) # vmap over axis 0 of params, state_means and state_covs\n",
    "    )(\n",
    "        hmc_param_samples,\n",
    "        t_emissions_train[hmc_start_idx_forecast[0]:hmc_stop_idx_forecast[0]],\n",
    "        hmc_forecasted_train.forecasted_state_means,\n",
    "        hmc_forecasted_train.forecasted_state_covariances,\n",
    "        None,\n",
    "        EKFHyperParams(),\n",
    "        next(keys),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx_filter_hmc = hmc_start_idx_filter[0]\n",
    "stop_idx_filter_hmc = hmc_stop_idx_filter[0]\n",
    "start_idx_forecast_hmc = hmc_start_idx_forecast[0]\n",
    "stop_idx_forecast_hmc = hmc_stop_idx_forecast[0]\n",
    "\n",
    "# Auxiliary function to split parameter samples into a list\n",
    "def split_params(params, index):\n",
    "    \"\"\"Extracts the specific index from each parameter in the structure.\"\"\"\n",
    "    return jax.tree_map(lambda x: x[index], params)\n",
    "\n",
    "# Split the emission functions into a list\n",
    "emission_function_list = [split_params(hmc_param_samples.emissions.emission_function, i) for i in range(hmc_N_samples)]\n",
    "# now extract the .f function from each of the emission functions\n",
    "emission_function_f_list = [x.f for x in emission_function_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance of filtering and forecasting on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the true states and emissions, and the EKF estimates\n",
    "for t_start, t_end in [\n",
    "        (None, None), # Plot all\n",
    "        (T0, T_forecast_end), # Plot from T0 until T_forecast_end, i.e., filtering and forecasting\n",
    "        (T0, T_filter_end), # Plot from T0 until T_forecast_end, i.e., filtering\n",
    "        (T_filter_end, T_forecast_end) # Plot from T_filter_end until T_forecast_end, i.e., forecasting\n",
    "    ]:\n",
    "    plot_advanced2(\n",
    "        time_grid_all=t_emissions_train,\n",
    "        true_states=true_states_train,\n",
    "        true_emissions_noisy=true_emissions_train,\n",
    "        emission_function=emission_function_f_list,\n",
    "        time_grid_filter=t_emissions_train[start_idx_filter_hmc:stop_idx_filter_hmc],\n",
    "        model_filtered_states=hmc_filtered_train.filtered_means,\n",
    "        time_grid_forecast=t_emissions_train[start_idx_forecast_hmc:stop_idx_forecast_hmc],\n",
    "        model_forecast_states=hmc_forecasted_train.forecasted_state_means,\n",
    "        t_start=t_start,\n",
    "        t_end=t_end,\n",
    "        N_samples=hmc_N_samples,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# include initial params for comparison\n",
    "plot_all_cdnlgssm_param_posteriors(\n",
    "    param_samples=hmc_param_samples,\n",
    "    param_properties=learnable_props,\n",
    "    init_params=initial_learnable_params,\n",
    "    true_params=true_params,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omit initial params for easy viewing of region of high probability\n",
    "plot_all_cdnlgssm_param_posteriors(\n",
    "    param_samples=hmc_param_samples,\n",
    "    param_properties=learnable_props,\n",
    "    # init_params=initial_learnable_params,\n",
    "    true_params=true_params,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hduq_nodynamax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
